```yaml
---
title: "Car Ownership Cost Analysis"
authors: "Geisol and Maria"
output: html_document
---


# Introduction

In this project, we analyze webscraped car ad data (from Blocket) along with vehicle data from Transportstyrelsen and insurance estimates.  
Our goal is to build a linear model to predict the yearly cost of car ownership.

---


```{r setup, message=FALSE, warning=FALSE}
# Load Packages
library(tidyverse)
library(readxl)
install.packages("fastDummies")
library(fastDummies)
install.packages("corrplot")
library(corrplot)
install.packages("rsample")
library(rsample)
install.packages("GGally")
library(GGally)
library(ggplot2)
library(dplyr)
install.packages("ggcorrplot")
library(ggcorrplot)


# Read the data into R (adjust file name if needed)
cars_raw <- read_excel("dataset_final.xlsx")

# Step 1: Convert character columns that look numeric (e.g., "1042") into actual numbers
cars_clean <- cars_raw %>%
  mutate(across(
    where(is.character),
    ~ ifelse(
        grepl("^[0-9.,]+$", .x),
        suppressWarnings(as.numeric(gsub(",", "", .x))),
        .x
      )
  )) %>%
  # Step 2: Convert energy consumption to numeric and replace NAs with 0
  mutate(`Energif√∂rbrukning (Wh/km)` = replace_na(as.numeric(`Energif√∂rbrukning (Wh/km)`), 0))

glimpse(cars_clean)

# Rule of thumb: a car loses between 15‚Äì20% of its value per year
# Source: https://exchange.aaa.com/automotive/car-buying-and-selling/car-resale-value
# ‚ÄúIf I buy this used car today for 120000 kr, how much will it lose in value each year going forward?‚Äù
# Annual depreciation = price √ó 0.15

cars_clean$"V√§rdeminskning (kr) per √•r" <- round(cars_clean$`Pris (kr)` * 0.15, 0)

# If I pay 20% myself and borrow the rest at 7.45% annual interest, this shows how much I pay in interest cost per year
cars_clean$"L√•n (kr) per √•r" <- round(cars_clean$`Pris (kr)` * 0.80 * 0.0745, 0)

# Set current fuel and electricity prices (kr per liter or kWh)
pris_bensin <- 15.54   # kr/liter
pris_diesel <- 16.59   # kr/liter
pris_el <- 1.50        # kr/kWh

# Create column for fuel cost based on fuel type and consumption
cars_clean$"Drivmedelskostnad (kr) f√∂r 10000 km" <- NA  # Initialize column

# Bensin (Gasoline)
bensin_index <- grepl("Bensin", cars_clean$Br√§nsle, ignore.case = TRUE)
cars_clean$"Drivmedelskostnad (kr) f√∂r 10000 km"[bensin_index] <- round(cars_clean$`Br√§nslef√∂rbrukning (l / 100 km)`[bensin_index] * 100 * pris_bensin, 0)

# Diesel
diesel_index <- grepl("Diesel", cars_clean$Br√§nsle, ignore.case = TRUE)
cars_clean$"Drivmedelskostnad (kr) f√∂r 10000 km"[diesel_index] <- round(cars_clean$`Br√§nslef√∂rbrukning (l / 100 km)`[diesel_index] * 100 * pris_diesel, 0)

# Hybrid or environmentally friendly fuel
hybrid_index <- grepl("Milj√∂br√§nsle|Hybrid", cars_clean$Br√§nsle, ignore.case = TRUE)
cars_clean$"Drivmedelskostnad (kr) f√∂r 10000 km"[hybrid_index] <- round(cars_clean$`Br√§nslef√∂rbrukning (l / 100 km)`[hybrid_index] * 100 * pris_bensin, 0)

# Electric cars (electricity only)
elbilar_index <- !is.na(cars_clean$`Energif√∂rbrukning (Wh/km)`) & is.na(cars_clean$`Br√§nslef√∂rbrukning (l / 100 km)`)
cars_clean$"Drivmedelskostnad (kr) f√∂r 10000 km"[elbilar_index] <- round((cars_clean$`Energif√∂rbrukning (Wh/km)`[elbilar_index] / 1000) * 10000 * pris_el, 0)

# Plug-in hybrids (both electricity and fuel)
laddhybrid_index <- !is.na(cars_clean$`Energif√∂rbrukning (Wh/km)`) & !is.na(cars_clean$`Br√§nslef√∂rbrukning (l / 100 km)`)

# Assume 50% of driving is electric and 50% is fuel-based
el_kostnad <- (cars_clean$`Energif√∂rbrukning (Wh/km)`[laddhybrid_index] / 1000) * 5000 * pris_el
br√§nsle_kostnad <- cars_clean$`Br√§nslef√∂rbrukning (l / 100 km)`[laddhybrid_index] * 50 * pris_bensin
cars_clean$"Drivmedelskostnad (kr) f√∂r 10000 km"[laddhybrid_index] <- round(el_kostnad + br√§nsle_kostnad, 0)

# To avoid multicollinearity in regression (i.e. one variable being a perfect combination of others),
# we use k‚Äì1 dummy variables for k categories




library(fastDummies)

# 1. Skapa dummyvariabler f√∂r Br√§nsle (men anv√§nd faktorer i modellen)
cars_clean <- dummy_cols(
  cars_clean,
  select_columns = "Br√§nsle",
  remove_first_dummy = TRUE,    # referenskategori: El
  remove_selected_columns = FALSE
)
cars_clean$Br√§nsle <- factor(cars_clean$Br√§nsle)
cars_clean$Br√§nsle <- relevel(cars_clean$Br√§nsle, ref = "El")


# 2. Gruppindela Biltyp till f√§rre kategorier
cars_clean <- cars_clean %>%
  mutate(
    Biltyp = case_when(
      Biltyp %in% c("Halvkombi", "Kombi", "Sedan") ~ "Personbil",
      Biltyp %in% c("SUV", "Familjebuss", "Yrkesfordon", "Sk√•pbil") ~ "Storbil",
      Biltyp %in% c("Coup√©", "Cab") ~ "Sportbil",
      TRUE ~ "Annat"
    ),
    Biltyp = factor(Biltyp)
  )

# 3. Skapa slutlig modell-dataset d√§r vi anv√§nder *bara* faktorer
cars_clean_inf <- cars_clean %>%
  mutate(
    Helf√∂rs√§kring_log = log(`Helf√∂rs√§kring (kr / √•r)`),
    Pris_log = log(`Pris (kr)`),
    Skatt_log = log(`Fordonsskatt (kr / √•r)` + 1),
    M√§tar_log = log(`M√§tarst√§llning (km)` + 1),
    CO2_log = log(`Koldioxidutsl√§pp blandad (NEDC) g/km` + 1),
    Br√§nslef√∂rb_log = log(`Br√§nslef√∂rbrukning (l / 100 km)` + 1)
  ) %>%
  select(
    Helf√∂rs√§kring_log,
    H√§stkrafter,
    Modell√•r,
    M√§tar_log,
    CO2_log,
    Br√§nslef√∂rb_log,
    Br√§nsle,
    Biltyp,
    Pris_log,
    Skatt_log
  )


glimpse(cars_clean_inf)

# Correlation with Helf√∂rs√§kringen as target
#Pearson-korrelationen f√•ngar endast linj√§ra samband, men vi kan √§nd√• ta bort variablerna som har mycket h√∂g korrelation
cars_clean_inf %>%
  select_if(is.numeric) %>%
  summarise(across(everything(), ~ cor(.x, cars_clean_inf[["Helf√∂rs√§kring_log"]], use = "complete.obs"))) %>%
  pivot_longer(cols = everything(), names_to = "Variable", values_to = "Correlation") %>%
  arrange(desc(abs(Correlation)))





# We now train model with AIC that means it will only take in those features that are meaningful
model_f <- lm(`Helf√∂rs√§kring_log` ~ ., data = cars_clean_inf)
summary(model_f)
confint(model_f)


plot(model_f)
library(car)
vif(model_f)

____________________________________________________________
#statistical inference
#Use the entire dataset (cars_model) for one regression model
#Report: summary(model), p-values, confidence intervals, and interpretations

Statistical inference

# F√∂rs√§kringens beroende av h√§stkrafter, modell√•r, br√§nsletyp etc.
mod_forsakring <- lm(`Helf√∂rs√§kring (kr / √•r)` ~ H√§stkrafter + Modell√•r + Br√§nsle_Diesel + Br√§nsle_El, data = cars_clean)

# Fordonsskattens beroende av modell√•r, h√§stkrafter etc.
mod_skatt <- lm(`Fordonsskatt (kr / √•r)` ~ Modell√•r + H√§stkrafter + Br√§nsle_Diesel + Br√§nsle_El, data = cars_clean)

















________________________________________
# Create the column '√Ñgandekostnad (kr) per √•r' which sums all recurring yearly ownership costs

# Note:
# - The 20% down payment (the part we paid from our savings) is not included in the yearly cost,
#   as it is a one-time expense and does not impact ongoing ownership costs.
# - We also do not account for unpredictable costs such as repairs, accidents, insurance deductibles, or parts replacement.

cars_clean$`√Ñgandekostnad (kr) per √•r` <- round(
  cars_clean$`Fordonsskatt (kr / √•r)` +                      # vehicle tax
  cars_clean$`Helf√∂rs√§kring (kr / √•r)` +                     # insurance
  cars_clean$`L√•n (kr) per √•r` +                              # loan interest
  cars_clean$`Drivmedelskostnad (kr) f√∂r 10000 km` +          # fuel or electricity
  cars_clean$`V√§rdeminskning (kr) per √•r` +                   # annual depreciation
  800 +                                                       # tire wear
  4000,                                                       # service
  0                                                           # round to whole kronor
)
________________________________________________________________

Here begins EDA


#Remove variables that we alredy know (ex. Derived directly from Pris or Koldioxidutsl√§pp vs Br√§nslef√∂rbrukning) are highly correlated with the target or redundant with each other

# Select only numeric columns
numeric_cols <- cars_clean %>%
  select(where(is.numeric))

# Remove specific columns that are either redundant or derived from each other
cols_to_remove <- c(
  "Pris (kr)",
  "V√§rdeminskning (kr) per √•r",
  "L√•n (kr) per √•r",
  "Koldioxidutsl√§pp blandad (NEDC) g/km"
)

# Filter the cleaned set
numeric_filtered <- numeric_cols %>%
  select(-all_of(cols_to_remove))

  
# Compute and plot the correlation matrix
cor_matrix_cleaned <- cor(numeric_filtered, use = "complete.obs")

corrplot(
  cor_matrix_cleaned,
  method = "color",
  type = "upper",
  tl.cex = 0.8,
  number.cex = 0.7,
  tl.col = "black",
  addCoef.col = "black"
)


# Remove columns that are weakly correlated or redundant with stronger predictors
# The goal is to simplify the model while preserving predictive power

# Remove variables that are weakly correlated or redundant with stronger predictors
# Goal: simplify the model while preserving interpretability and avoiding multicollinearity

cars_model <- cars_clean %>%
  select(
    `√Ñgandekostnad (kr) per √•r`,     # üéØ Target variable we're predicting

    # Keep these predictors (they are independent and showed predictive value)
    H√§stkrafter,                     # Strong linear relationship with cost ‚Äî significant predictor
    Modell√•r,                        # Newer cars tend to cost more ‚Äî significant
    `M√§tarst√§llning (km)`,          # Optional ‚Äî weak to moderate effect, but useful to test
    Br√§nsle_Diesel,                 # Fuel type dummy ‚Äî significant positive effect on cost
    Br√§nsle_El,                     # Fuel type dummy ‚Äî significantly reduces cost
    `Br√§nsle_Milj√∂br√§nsle/Hybrid`   # Fuel type dummy ‚Äî moderately reduces cost

    # Remove the following:
    # - BiltypPersonbil
    # - BiltypSportbil
    # - BiltypStorbil
    # Reason: All three had high p-values in the linear model (not statistically significant)
    #         and did not meaningfully contribute to predicting ownership cost.
    #         Removing them simplifies the model without hurting performance.

    # Also already excluded in earlier steps:
    # - Pris, V√§rdeminskning, L√•n, F√∂rs√§kring, Skatt, Drivmedelskostnad, Energif√∂rbrukning
    # Because they were either directly used to compute the target or introduce target leakage
  )



# visualize how each numeric predictor relates to your target.
#‚ÄúDo we have multicollinearity?‚Äù Yes
ggpairs(select(cars_model, where(is.numeric)))

library(tidyr)
library(dplyr)

# 1. Select numeric predictors, excluding the target
num_predictors <- cars_model %>%
  select(where(is.numeric)) %>%
  select(-`√Ñgandekostnad (kr) per √•r`)

# 2. Add the target back for plotting
plot_data <- bind_cols(
  num_predictors,
  √Ñgandekostnad = cars_model$`√Ñgandekostnad (kr) per √•r`
)

# Convert to long format for ggplot
plot_data_long <- plot_data %>%
  pivot_longer(cols = -√Ñgandekostnad, names_to = "Variable", values_to = "Value")

library(ggplot2)

ggplot(plot_data_long, aes(x = Value, y = √Ñgandekostnad)) +
  geom_point(alpha = 0.3, size = 0.8) +
  geom_smooth(method = "loess", se = FALSE, color = "steelblue") +
  facet_wrap(~ Variable, scales = "free_x") +
  theme_minimal() +
  labs(
    title = "Predictors vs Yearly Ownership Cost",
    x = "Predictor Value",
    y = "Ownership Cost (kr/year)"
  )



____________________________________________________
#Building the predictive model
#Use a train/val/test split
#Fit the model on train, evaluate on val
#Report RMSE, R¬≤
#Mention how well the model generalizes

set.seed(123)  # for reproducibility

# First: split into training+validation and test sets (80/20)
split_1 <- initial_split(cars_model, prop = 0.8)
train_val <- training(split_1)
test <- testing(split_1)

# Further split train+val into train (70%) and validation (30%)
set.seed(123)

split_2 <- initial_split(train_val, prop = 0.7)
train <- training(split_2)
val <- testing(split_2)

#one should aim to have at least 10‚Äì15 rows per feature in a regression model. We are using <15 features - safe!

nrow(train) / ncol(train) # >10 ‚Üí we're good



# Build a linear model using all remaining predictors
model_lm <- lm(`√Ñgandekostnad (kr) per √•r` ~ ., data = train)

# View model summary
summary(model_lm)

