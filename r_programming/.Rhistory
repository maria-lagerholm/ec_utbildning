data          = tr %>% select(-id, -fordonsbenamning, -handelsbeteckning, -pris),
num.trees     = p$num.trees,
mtry          = p$mtry,
min.node.size = p$min.node.size,
max.depth     = p$max.depth
)
pred <- predict(mod, va)$predictions
rmse_vec(truth = va$pris_log, estimate = pred)
})
tibble(
num.trees     = p$num.trees,
mtry          = p$mtry,
min.node.size = p$min.node.size,
max.depth     = p$max.depth,
RMSE_log_CV   = mean(fold_metrics)
)
})
# Select best hyperparameters based on CV
best_params <- cv_results %>%
slice_min(RMSE_log_CV, n = 1)
# -----------------------------------------------------------
# Step 5: Train final model on entire training set
# -----------------------------------------------------------
final_model <- ranger(
pris_log ~ .,
data          = train %>% select(-id, -fordonsbenamning, -handelsbeteckning, -pris),
num.trees     = best_params$num.trees,
mtry          = best_params$mtry,
min.node.size = best_params$min.node.size,
max.depth     = best_params$max.depth,
importance    = "impurity"
)
# -----------------------------------------------------------
# Step 7: Evaluate RMSE (final hold-out test set)
# -----------------------------------------------------------
# Predictions on test set (hold-out)
test_pred_log <- predict(final_model, test)$predictions
test_pred_sek <- exp(test_pred_log)
# Calculate RMSE for test set
rmse_test_log <- rmse_vec(test$pris_log, test_pred_log)
rmse_test_sek <- rmse_vec(test$pris, test_pred_sek)
# Compute SEK equivalent of the CV RMSE_log (0.228)
# Using mean predicted price (SEK) from test set as scaling factor
mean_test_pred_sek <- mean(test_pred_sek)
rmse_cv_sek_equiv <- mean_test_pred_sek * best_params$RMSE_log_CV
# Step 8: Results (CV vs. Test)
results_summary <- tibble(
Dataset  = c("5-fold CV (grid-search)", "Test set (hold-out)"),
RMSE_log = round(c(best_params$RMSE_log_CV, rmse_test_log), 4),
RMSE_SEK = round(c(rmse_cv_sek_equiv, rmse_test_sek), 0)
)
print(results_summary)
# -----------------------------------------------------------
# Step 9: Residual Analysis – overpriced vs. underpriced cars
# -----------------------------------------------------------
test_results <- test %>%
mutate(
pred_log = test_pred_log,
pred_sek = test_pred_sek,
diff_sek = pris - pred_sek,
diff_pct = 100 * diff_sek / pred_sek
) %>%
select(id, fordonsbenamning, handelsbeteckning, pris, pred_sek, diff_sek, diff_pct)
overpriced  <- test_results %>% arrange(desc(diff_sek)) %>% slice_head(n = 10)
underpriced <- test_results %>% arrange(diff_sek) %>% slice_head(n = 10)
cat("\nTop 10 Overpriced Cars:\n")
print(overpriced)
cat("\nTop 10 Underpriced Cars:\n")
print(underpriced)
# -----------------------------------------------------------
# Step 10: Variable importance visualization
# -----------------------------------------------------------
vip(final_model, num_features = 10, bar = TRUE) +
ggtitle("Variable Importance (Top 10 Predictors)")
#| label: rf-price-prediction
#| message: false
#| warning: false
library(dplyr)
library(fastDummies)
library(janitor)
library(rsample)
library(ranger)
library(purrr)
library(yardstick)
library(tibble)
library(vip)
# -----------------------------------------------------------
# Step 1: Data Preparation (log-transformations & dummy vars)
# -----------------------------------------------------------
library(dplyr)
library(janitor)
# Define log-transform target columns
log_vars <- c(
"pris_log",
"fordonsskatt_log",
"helforsakring_log",
"hastkrafter_log",
"matarstallning_log"
)
# Clean and transform the dataset
cars_price <- cars_clean %>%
mutate(id = row_number()) %>%
transmute(
id,
fordonsbenamning = Fordonsbenämning,
handelsbeteckning = Handelsbeteckning,
pris = `Pris (kr)`,
pris_log = log(pris),
fordonsskatt_log = log(`Fordonsskatt (kr / år)` + 1),
helforsakring_log = log(`Helförsäkring (kr / år)` + 1),
hastkrafter_log = log(Hästkrafter + 1),
matarstallning_log = log(`Mätarställning (km)` + 1),
#co2 = `Koldioxidutsläpp blandad (NEDC) g/km`
) %>%
clean_names()
# -----------------------------------------------------------
# Step 2: Compute outlier thresholds before splitting
# -----------------------------------------------------------
compute_outlier_bounds <- function(df, columns, lower = 0.01, upper = 0.99) {
map(columns, function(col) {
tibble(
variable = col,
q_low = quantile(df[[col]], lower, na.rm = TRUE),
q_high = quantile(df[[col]], upper, na.rm = TRUE)
)
}) %>% bind_rows()
}
apply_outlier_filter <- function(df, bounds) {
for (i in seq_len(nrow(bounds))) {
col <- bounds$variable[i]
df <- df %>% filter(.data[[col]] >= bounds$q_low[i], .data[[col]] <= bounds$q_high[i])
}
df
}
outlier_bounds <- compute_outlier_bounds(cars_price, log_vars)
# -----------------------------------------------------------
# Step 3: Initial Split (80/20) stratified by log(price)
# -----------------------------------------------------------
set.seed(123)
split <- initial_split(cars_price, prop = 0.8, strata = pris_log)
train <- training(split)
test  <- testing(split)
# Apply outlier removal
train <- apply_outlier_filter(train, outlier_bounds)
test  <- apply_outlier_filter(test, outlier_bounds)
# -----------------------------------------------------------
# Step 4: Hyperparameter Grid Search via 5-fold Cross-validation
# -----------------------------------------------------------
set.seed(123)
folds <- vfold_cv(train, v = 5, strata = pris_log)
param_grid <- expand.grid(
num.trees     = c(50, 200),
mtry          = floor(ncol(train)/2),
min.node.size = c(1, 10),
max.depth     = c(2, 12)
)
cv_results <- purrr::map_dfr(seq_len(nrow(param_grid)), function(i) {
p <- param_grid[i, ]
fold_metrics <- map_dbl(folds$splits, function(spl) {
tr <- analysis(spl)
va <- assessment(spl)
mod <- ranger(
pris_log ~ .,
data          = tr %>% select(-id, -fordonsbenamning, -handelsbeteckning, -pris),
num.trees     = p$num.trees,
mtry          = p$mtry,
min.node.size = p$min.node.size,
max.depth     = p$max.depth
)
pred <- predict(mod, va)$predictions
rmse_vec(truth = va$pris_log, estimate = pred)
})
tibble(
num.trees     = p$num.trees,
mtry          = p$mtry,
min.node.size = p$min.node.size,
max.depth     = p$max.depth,
RMSE_log_CV   = mean(fold_metrics)
)
})
# Select best hyperparameters based on CV
best_params <- cv_results %>%
slice_min(RMSE_log_CV, n = 1)
# -----------------------------------------------------------
# Step 5: Train final model on entire training set
# -----------------------------------------------------------
final_model <- ranger(
pris_log ~ .,
data          = train %>% select(-id, -fordonsbenamning, -handelsbeteckning, -pris),
num.trees     = best_params$num.trees,
mtry          = best_params$mtry,
min.node.size = best_params$min.node.size,
max.depth     = best_params$max.depth,
importance    = "impurity"
)
# -----------------------------------------------------------
# Step 7: Evaluate RMSE (final hold-out test set)
# -----------------------------------------------------------
# Predictions on test set (hold-out)
test_pred_log <- predict(final_model, test)$predictions
test_pred_sek <- exp(test_pred_log)
# Calculate RMSE for test set
rmse_test_log <- rmse_vec(test$pris_log, test_pred_log)
rmse_test_sek <- rmse_vec(test$pris, test_pred_sek)
# Compute SEK equivalent of the CV RMSE_log (0.228)
# Using mean predicted price (SEK) from test set as scaling factor
mean_test_pred_sek <- mean(test_pred_sek)
rmse_cv_sek_equiv <- mean_test_pred_sek * best_params$RMSE_log_CV
# Step 8: Results (CV vs. Test)
results_summary <- tibble(
Dataset  = c("5-fold CV (grid-search)", "Test set (hold-out)"),
RMSE_log = round(c(best_params$RMSE_log_CV, rmse_test_log), 4),
RMSE_SEK = round(c(rmse_cv_sek_equiv, rmse_test_sek), 0)
)
print(results_summary)
# -----------------------------------------------------------
# Step 9: Residual Analysis – overpriced vs. underpriced cars
# -----------------------------------------------------------
test_results <- test %>%
mutate(
pred_log = test_pred_log,
pred_sek = test_pred_sek,
diff_sek = pris - pred_sek,
diff_pct = 100 * diff_sek / pred_sek
) %>%
select(id, fordonsbenamning, handelsbeteckning, pris, pred_sek, diff_sek, diff_pct)
overpriced  <- test_results %>% arrange(desc(diff_sek)) %>% slice_head(n = 10)
underpriced <- test_results %>% arrange(diff_sek) %>% slice_head(n = 10)
cat("\nTop 10 Overpriced Cars:\n")
print(overpriced)
cat("\nTop 10 Underpriced Cars:\n")
print(underpriced)
# -----------------------------------------------------------
# Step 10: Variable importance visualization
# -----------------------------------------------------------
vip(final_model, num_features = 10, bar = TRUE) +
ggtitle("Variable Importance (Top 10 Predictors)")
# -----------------------------------------------------------
# Step 9: Residual Analysis – overpriced vs. underpriced cars
# -----------------------------------------------------------
test_results <- test %>%
mutate(
pred_log = test_pred_log,
pred_sek = test_pred_sek,
diff_sek = pris - pred_sek,
diff_pct = 100 * diff_sek / pred_sek
) %>%
select(id, fordonsbenamning, handelsbeteckning, pris, pred_sek, diff_sek, diff_pct)
overpriced  <- test_results %>% arrange(desc(diff_sek)) %>% slice_head(n = 10)
underpriced <- test_results %>% arrange(diff_sek) %>% slice_head(n = 10)
cat("\nTop 10 Overpriced Cars:\n")
print(overpriced)
cat("\nTop 10 Underpriced Cars:\n")
print(underpriced)
# -----------------------------------------------------------
# Step 10: Variable importance visualization
# -----------------------------------------------------------
vip(final_model, num_features = 10, bar = TRUE) +
ggtitle("Variable Importance (Top 10 Predictors)")
test_results <- test %>%
mutate(
pred_log = test_pred_log,
pred_sek = test_pred_sek,
diff_sek = pris - pred_sek,
diff_pct = 100 * diff_sek / pred_sek
) %>%
select(id, fordonsbenamning, handelsbeteckning, pris, pred_sek, diff_sek, diff_pct)
overpriced  <- test_results %>% arrange(desc(diff_sek)) %>% slice_head(n = 10)
underpriced <- test_results %>% arrange(diff_sek) %>% slice_head(n = 10)
cat("\nTop 10 Overpriced Cars:\n")
print(overpriced)
cat("\nTop 10 Underpriced Cars:\n")
print(underpriced)
# -----------------------------------------------------------
# Step 10: Variable importance visualization
# -----------------------------------------------------------
vip(final_model, num_features = 10, bar = TRUE)
test_results <- test %>%
mutate(
pred_log = test_pred_log,
pred_sek = test_pred_sek,
diff_sek = pris - pred_sek,
diff_pct = 100 * diff_sek / pred_sek
) %>%
select(id, fordonsbenamning, handelsbeteckning, pris, pred_sek, diff_sek, diff_pct)
overpriced  <- test_results %>% arrange(desc(diff_sek)) %>% slice_head(n = 5)
underpriced <- test_results %>% arrange(diff_sek) %>% slice_head(n = 5)
cat("\nTop 5 Overpriced Cars:\n")
print(overpriced)
cat("\nTop 5 Underpriced Cars:\n")
print(underpriced)
# -----------------------------------------------------------
# Step 10: Variable importance visualization
# -----------------------------------------------------------
vip(final_model, num_features = 10, bar = TRUE)
# Create folder to store SCB data
if (!dir.exists("scb")) {
dir.create("scb")
}
# Install and load pxweb if needed
if (!require(pxweb)) install.packages("pxweb")
library(pxweb)
# Define query to SCB API: Number of passenger cars in traffic by model year and fuel type
query <- list(
"Fordonsår" = c("*"),              # all model years
"Drivmedel" = c("*"),              # all fuel types
"ContentsCode" = c("TK1001T1"),    # "Antal personbilar i trafik"
"Tid" = c("*")                     # all available years
)
# SCB API endpoint for passenger car statistics
url <- "https://api.scb.se/OV0104/v1/doris/sv/ssd/START/MI/MI0110/MI0110A/FordonF"
# Download data from SCB
data <- pxweb_get(url = url, query = query)
library(pxweb)
# Visa metadata för tabellen (alla möjliga variabler och värden)
url <- "https://api.scb.se/OV0104/v1/doris/sv/ssd/START/MI/MI0110/MI0110A/FordonF"
meta <- pxweb_get(url)
# Load package
library(pxweb)
# Skapa en mapp där vi kan spara data
if (!dir.exists("scb")) dir.create("scb")
# SCB API endpoint
url <- "https://api.scb.se/OV0104/v1/doris/sv/ssd/START/MI/MI0110/MI0110A/FordonF"
# Hämta metadata (struktur och möjliga värden)
meta <- pxweb_get_metadata(url)
# Ladda paket
library(pxweb)
# Skapa mapp för att spara SCB-data
if (!dir.exists("scb")) dir.create("scb")
# URL till tabellen: Antal personbilar i trafik efter fordonsår och drivmedel
url <- "https://api.scb.se/OV0104/v1/doris/sv/ssd/START/MI/MI0110/MI0110A/FordonF"
# Hämta metadata (variabler, möjliga värden, etc.)
meta <- pxweb::pxweb_get(url = url, query = NULL)
#| label: setup
#| message: false
#| warning: false
#| results: hide
packages <- c(
"tidyverse", "readxl", "fastDummies", "corrplot",
"rsample", "GGally", "ggcorrplot", "car", "xgboost", "yardstick", "tibble", "ranger", "glmnet", "vip", "httr", "jsonlite"
)
idx <- packages %in% rownames(installed.packages())
if (any(!idx)) install.packages(packages[!idx])
suppressPackageStartupMessages(
invisible(lapply(packages, library, character.only = TRUE))
)
library(httr)
library(jsonlite)
# Endpoint & JSON-body
url <- "https://api.scb.se/ov0104/v2beta/api/v2/tables/MI/MI0110/MI0110A/fordonf/data"
body <- list(
query = list(
list(code = "Fordonsår", selection = list(filter = "item", values = c("2023"))),
list(code = "Drivmedel", selection = list(filter = "item", values = c("01", "02"))),  # Justera efter metadata
list(code = "ContentsCode", selection = list(filter = "item", values = c("TK1001T1"))),
list(code = "Tid", selection = list(filter = "item", values = c("2023")))
),
response = list(format = "json-stat2")
)
# Skicka POST-förfrågan
res <- POST(url, body = body, encode = "json")
# Kontrollera svar
if (res$status_code == 200) {
data <- content(res, as = "text", encoding = "UTF-8")
parsed <- fromJSON(data)
print(parsed)
} else {
print(paste("Fel vid hämtning:", res$status_code))
}
library(httr)
library(jsonlite)
# Korrekt URL till tabellen
url <- "https://api.scb.se/OV0104/v2beta/api/v2/tables/MI/MI0110/MI0110A/FordonF/data"
# JSON-kropp – se till att dina valider är exakt som i metadata
body <- list(
query = list(
list(code = "Fordonsår", selection = list(filter = "item", values = c("2023"))),
list(code = "Drivmedel", selection = list(filter = "item", values = c("01", "02"))),
list(code = "ContentsCode", selection = list(filter = "item", values = c("TK1001T1"))),
list(code = "Tid", selection = list(filter = "item", values = c("2023")))
),
response = list(format = "json-stat2")
)
# Skicka förfrågan
res <- POST(url, body = body, encode = "json")
# Svara
if (res$status_code == 200) {
data <- content(res, as = "text", encoding = "UTF-8")
parsed <- fromJSON(data)
print(parsed)
} else {
cat("Fel vid hämtning:", res$status_code, "\n")
cat("Kontrollera att URL och koder är korrekta.")
}
}
library(httr)
library(jsonlite)
# Korrekt URL till tabellen
url <- "https://api.scb.se/OV0104/v2beta/api/v2/tables/MI/MI0110/MI0110A/FordonF/data"
# JSON-kropp – se till att dina valider är exakt som i metadata
body <- list(
query = list(
list(code = "Fordonsår", selection = list(filter = "item", values = c("2023"))),
list(code = "Drivmedel", selection = list(filter = "item", values = c("01", "02"))),
list(code = "ContentsCode", selection = list(filter = "item", values = c("TK1001T1"))),
list(code = "Tid", selection = list(filter = "item", values = c("2023")))
),
response = list(format = "json-stat2")
)
# Skicka förfrågan
res <- POST(url, body = body, encode = "json")
# Svara
if (res$status_code == 200) {
data <- content(res, as = "text", encoding = "UTF-8")
parsed <- fromJSON(data)
print(parsed)
} else {
cat("Fel vid hämtning:", res$status_code, "\n")
cat("Kontrollera att URL och koder är korrekta.")
}
library(httr)
library(jsonlite)
metadata_url <- "https://api.scb.se/OV0104/v2beta/api/v2/tables/MI/MI0110/MI0110A/FordonF"
res_meta <- GET(metadata_url)
if (res_meta$status_code == 200) {
meta_data <- content(res_meta, as = "text", encoding = "UTF-8")
meta_parsed <- fromJSON(meta_data)
print(meta_parsed)
} else {
cat("Failed to retrieve metadata. Status code:", res_meta$status_code, "\n")
}
install.packages("pxweb")
install.packages("pxweb")
#| label: setup
#| message: false
#| warning: false
#| results: hide
packages <- c(
"tidyverse", "readxl", "fastDummies", "corrplot",
"rsample", "GGally", "ggcorrplot", "car", "xgboost", "yardstick", "tibble", "ranger", "glmnet", "vip", "httr", "jsonlite", "pxweb"
)
idx <- packages %in% rownames(installed.packages())
if (any(!idx)) install.packages(packages[!idx])
suppressPackageStartupMessages(
invisible(lapply(packages, library, character.only = TRUE))
)
# Ladda nödvändiga paket
library(httr)
library(jsonlite)
# Skapa en mapp för att spara SCB-data
if (!dir.exists("scb")) dir.create("scb")
# Ange URL till tabellen: Antal personbilar i trafik efter fordonsår och drivmedel
url <- "https://api.scb.se/OV0104/v2beta/api/v2/tables/MI/MI0110/MI0110A/FordonF/data"
# Skapa förfrågningskroppen (body) med önskade parametrar
body <- list(
query = list(
list(code = "Fordonsår", selection = list(filter = "item", values = c("2023"))),
list(code = "Drivmedel", selection = list(filter = "item", values = c("01", "02"))),
list(code = "ContentsCode", selection = list(filter = "item", values = c("TK1001T1"))),
list(code = "Tid", selection = list(filter = "item", values = c("2023")))
),
response = list(format = "json-stat2")
)
# Skicka POST-förfrågan till SCB:s API
res <- POST(url, body = body, encode = "json")
# Kontrollera om förfrågan lyckades
if (res$status_code == 200) {
# Extrahera och konvertera svaret till text
data_text <- content(res, as = "text", encoding = "UTF-8")
# Konvertera JSON-stat till en R-lista
data_list <- fromJSON(data_text)
# Spara data till en fil i mappen "scb"
write(data_text, file = "scb/fordon_data.json")
# Visa en sammanfattning av datan
print(data_list)
} else {
# Om förfrågan misslyckades, skriv ut felmeddelande
cat("Fel vid hämtning:", res$status_code, "\n")
cat("Kontrollera att URL och parametrar är korrekta.\n")
}
# Install and load pxweb if you haven't already
if (!require(pxweb)) install.packages("pxweb")
library(pxweb)
# 1) Launch the interactive browser starting at SCB’s API root
#    A small browser window will pop up—navigate to the exact table you want,
#    and when you’re done, hit “Done” to return your query and URL.
px_int <- pxweb_interactive("https://api.scb.se/OV0104/v1/doris/sv/ssd/START/MI/MI0110/MI0110A")
install.packages("remotes")  # or: install.packages("devtools")
library(remotes)             # or: library(devtools)
remove.packages("pxweb")
remove.packages("pxweb")
library(remotes)
remotes::install_github("rOpenGov/pxweb")
Sys.setlocale(locale = "UTF-8")
# Get data from SCB (Statistics Sweden)
d <- pxweb_interactive("api.scb.se")
library(pxweb)
# Get data from SCB (Statistics Sweden)
d <- pxweb_interactive("api.scb.se")
remove.packages("pxweb")
remotes::install_github("rOpenGov/pxweb")
library(pxweb)
Sys.setlocale(locale = "UTF-8")
# Get data from SCB (Statistics Sweden)
d <- pxweb_interactive("api.scb.se")
remove.packages("pxweb")  # again, just in case
unlink("~/.cache/R/pxweb", recursive = TRUE)
remotes::install_github("rOpenGov/pxweb", force = TRUE, build_vignettes = FALSE)
library(pxweb)
Sys.setlocale(locale = "UTF-8")
# Get data from SCB (Statistics Sweden)
d <- pxweb_interactive("api.scb.se")
